# app.py  â€“Â StreamlitÂ +Â OpenAI Assistants demo
import streamlit as st
import openai, json, time, os
from pathlib import Path

# 1ï¸âƒ£  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Secure key handling
openai.api_key = st.secrets["OPENAI_API_KEY"]      # store in .streamlit/secrets.toml
ASSISTANT_ID   = st.secrets["ASSISTANT_ID"]        # created once; keep the id

st.set_page_config(page_title="TalentMatch Demo", page_icon="ğŸ§©")
st.title("ğŸ” TalentMatchÂ â€“Â Teamâ€‘builder demo")

# 2ï¸âƒ£  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UI: project brief + batch CV upload
project_brief = st.text_area("Paste the project brief", height=200)
cv_files      = st.file_uploader(
    "Upload consultant CVs (.txt)", type="txt", accept_multiple_files=True
)

if st.button("Generate team options", disabled=not(project_brief and cv_files)):
    # 3ï¸âƒ£  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Read file contents
    cvs = [f.read().decode("utfâ€‘8", errors="ignore") for f in cv_files]

    user_payload = json.dumps({
        "project_description": project_brief,
        "cvs": cvs
    })

    # 4ï¸âƒ£  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Create a new thread with the user message
    try:
        thread = openai.beta.threads.create(
            messages=[{"role": "user", "content": user_payload}]
        )
    except Exception as e:
        st.error(f"Thread creation failed: {e}")
        st.stop()

    # 5ï¸âƒ£  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Start the run (stream=True for token streaming)
    with st.spinner("Talking to TalentMatchâ€‘GPTâ€¦"):
        try:
            stream = openai.beta.threads.runs.create(
                thread_id=thread.id,
                assistant_id=ASSISTANT_ID,
                stream=True            # ğŸ”¥ realâ€‘time tokens
            )
        except Exception as e:
            st.error(f"Run failed: {e}")
            st.stop()

        # 6ï¸âƒ£  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Consume the stream chunkâ€‘byâ€‘chunk
        response_md = st.empty()        # placeholder container
        collected   = ""                # incremental buffer

        for chunk in stream:
            if "content" in chunk.delta:
                token = chunk.delta.content
                collected += token
                response_md.markdown(collected, unsafe_allow_html=True)

        # 7ï¸âƒ£  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.success("Finished âœ”")

        # Optional: show the raw JSON if you want to debug
        with st.expander("Raw response JSON"):
            st.json(stream.done())
